{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFimmhVCtu2f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2AliWJ_turk"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/intel_image_data/archive.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6QLyVc6hQG0"
      },
      "outputs": [],
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3hIA7JmherT"
      },
      "outputs": [],
      "source": [
        "#checking for device\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7YcQn8DhkYZ",
        "outputId": "05d8d93f-f5c6-44e7-b0ee-cfc14f5d3c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmhTQ4iRhkNa"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsbdbohRhkB9"
      },
      "outputs": [],
      "source": [
        "#Dataloader\n",
        "#Path for training and testing directory\n",
        "\n",
        "\n",
        "\n",
        "train_path='/content/drive/MyDrive/dataset_9010/dataset_9010/malimg_dataset/train'\n",
        "test_path='/content/drive/MyDrive/dataset_9010/dataset_9010/malimg_dataset/validation' \n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=4, shuffle=True\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=4, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQiJ8uk58yMM",
        "outputId": "3674a042-756d-4173-b32a-5d9a478ef0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Named explicitly:\n",
            "\t 69\n"
          ]
        }
      ],
      "source": [
        "for name in glob.glob('/content/drive/MyDrive/dataset_9010/dataset_9010/malimg_dataset/train'):\n",
        "    print('\\t', len(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkERW7Y8c3b"
      },
      "outputs": [],
      "source": [
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYcIOvachj1G",
        "outputId": "8e65550f-1b0e-4cf0-c68c-25f635b09beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.P', 'C2LOP.gen!g', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A'] 25\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "print(classes,len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMJ6O5t-hjqI"
      },
      "outputs": [],
      "source": [
        "#CNN Network\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=25):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Input shape= (4,3,150,150)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output\n",
        "            \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02_0gtvRq48-"
      },
      "outputs": [],
      "source": [
        "\n",
        "model=ConvNet(num_classes=25).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MITKqdvgq4yW"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Optmizer and loss function\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEzV1GSCrFYl",
        "outputId": "b5da059b-87ba-4356-edb4-14d99f592bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n"
          ]
        }
      ],
      "source": [
        "# calculating the size of training and testing images\n",
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
        "print(train_count,test_count)\n",
        "\n",
        "\n",
        "# for train_count in glob.glob('/content/drive/MyDrive/dataset_9010/dataset_9010/malimg_dataset/train'):\n",
        "#     print('\\t', len(name))\n",
        "\n",
        "# for test_count in glob.glob('/content/drive/MyDrive/dataset_9010/dataset_9010/malimg_dataset/validation'):\n",
        "#     print('\\t', len(name))\n",
        "\n",
        "# print(train_count,test_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7u726V38Dh-",
        "outputId": "5eccd9e4-9cfb-4469-8fbc-90fd402a9101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J68kA4E8q4iG"
      },
      "outputs": [],
      "source": [
        "num_epochs=4\n",
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}